{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler, RobustScaler\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.ensemble import IsolationForest\n",
    "from sklearn.neighbors import LocalOutlierFactor\n",
    "\n",
    "from itertools import product\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "from sklearn.experimental import enable_iterative_imputer\n",
    "from sklearn.impute import IterativeImputer\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "from category_encoders import TargetEncoder\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.tree import DecisionTreeRegressor, plot_tree\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import train_test_split,GridSearchCV\n",
    "from sklearn.metrics import r2_score, mean_squared_error, mean_absolute_error\n",
    "\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_scaler(data):\n",
    "    data_copy = data.copy()\n",
    "    for col in data.columns:\n",
    "        mean_data = data_copy[col].mean()\n",
    "        range_data = data_copy[col].max()-data_copy[col].min()\n",
    "        data_copy[col] = data_copy[col].apply(lambda x: (x-mean_data)/range_data)\n",
    "    return data_copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def percent_outs(array):\n",
    "    length = len(array)\n",
    "    neg_count = sum(array==-1)\n",
    "    p_outs = neg_count/length*100\n",
    "    return p_outs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def metricas(y_train, y_train_pred, y_test, y_test_pred):\n",
    "    metricas = {\n",
    "    'train': {\n",
    "        'r2_score': r2_score(y_train, y_train_pred),\n",
    "        'MAE': mean_absolute_error(y_train, y_train_pred),\n",
    "        'MSE': mean_squared_error(y_train, y_train_pred),\n",
    "        'RMSE': np.sqrt(mean_squared_error(y_train, y_train_pred))\n",
    "    },\n",
    "    'test': {\n",
    "        'r2_score': r2_score(y_test, y_test_pred),\n",
    "        'MAE': mean_absolute_error(y_test, y_test_pred),\n",
    "        'MSE': mean_squared_error(y_test, y_test_pred),\n",
    "        'RMSE': np.sqrt(mean_squared_error(y_test, y_test_pred))\n",
    "\n",
    "    }\n",
    "}\n",
    "    return metricas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "params_tree = {\n",
    "    'max_depth': [6, 8, 10, 20],\n",
    "    'min_samples_split': [10, 50],\n",
    "    'min_samples_leaf': [10, 50],\n",
    "    'max_leaf_nodes': [10, 20, 40, 80, 160]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ml_model(df, params_tree, scaler_type = \"rob\", outlier_threshold = 70, outlier_imputer = RandomForestRegressor()):\n",
    "    df[\"postalCode\"] = df[\"postalCode\"].astype(\"string\")\n",
    "    df_numeric = df.select_dtypes(\"number\").drop(columns=\"price\")\n",
    "    \n",
    "    if scaler_type == \"rob\":\n",
    "        scaler = RobustScaler()\n",
    "    elif scaler_type == \"minmax\":\n",
    "        scaler = MinMaxScaler()\n",
    "    elif scaler_type == \"stand\":\n",
    "        scaler = StandardScaler()\n",
    "    elif scaler_type == \"norm\":\n",
    "        numeric_scaled = normalize_scaler(df_numeric)\n",
    "\n",
    "    numeric_scaled = pd.DataFrame(scaler.fit_transform(df_numeric), columns=df_numeric.columns)\n",
    "    \n",
    "    df[df_numeric.columns] = numeric_scaled\n",
    "    df_numeric = df.select_dtypes('number')\n",
    "    ests = np.linspace(1,1000, 5, dtype = int)\n",
    "    conts = np.linspace(0.01,0.2,5)\n",
    "\n",
    "    forest_arg_combis = list(product(ests, conts))\n",
    "    print(\"Applying IFO\")\n",
    "    for n,m in tqdm(forest_arg_combis):\n",
    "        iforest = IsolationForest(random_state=42, n_estimators=n, contamination=m, n_jobs=12)\n",
    "        df[f\"iforest_{n}_{m:.3f}\"] = iforest.fit_predict(X=df_numeric)\n",
    "    df_forest = df.filter(like=\"iforest\")\n",
    "    \n",
    "    percentages = df_forest.apply(percent_outs, axis=1)\n",
    "    df_filtered_1 = df[percentages<outlier_threshold]\n",
    "\n",
    "    df_filtered_1 = df_filtered_1.drop(columns = df_filtered_1.filter(like=\"iforest\").columns)\n",
    "\n",
    "    df_numeric_filtered_1 = df_filtered_1.select_dtypes(\"number\")\n",
    "    \n",
    "    neighs = np.linspace(15,45,5, dtype=int)\n",
    "    lof_combis = list(product(neighs, conts))\n",
    "    print(\"Applying LOF\")\n",
    "    for neighbour, contaminacion in tqdm(lof_combis):\n",
    "        lof = LocalOutlierFactor(n_neighbors=neighbour, contamination=contaminacion, n_jobs=-1)\n",
    "        df_filtered_1[f\"lof_{neighbour}_{contaminacion:.3f}\"] = lof.fit_predict(X = df_numeric_filtered_1)\n",
    "\n",
    "    df_lof = df_filtered_1.filter(like=\"lof\")\n",
    "\n",
    "    percentages_filter_1 = df_lof.apply(percent_outs, axis=1)\n",
    "    outliers = df_filtered_1[percentages_filter_1>outlier_threshold]\n",
    "    normals = df_filtered_1[percentages_filter_1<outlier_threshold]\n",
    "\n",
    "    df_filtered_1.loc[outliers.index, \"powerCV\"] = np.nan\n",
    "    df_filtered_1.loc[outliers.index, \"kilometer\"] = np.nan\n",
    "\n",
    "    df_filtered_1.reset_index(drop=True, inplace=True)\n",
    "    imputer = IterativeImputer(estimator=outlier_imputer)\n",
    "    imputed_cols = pd.DataFrame(imputer.fit_transform(X=df_filtered_1[[\"price\", \"powerCV\", \"kilometer\"]]), columns = [\"price\", \"powerCV\", \"kilometer\"])\n",
    "\n",
    "    df_final = df_filtered_1.drop(columns = df_filtered_1.filter(like=\"lof\").columns)\n",
    "    df_final[[\"price\", \"powerCV\", \"kilometer\"]] = imputed_cols\n",
    "\n",
    "    df_final.drop(columns=['name', 'model', 'postalCode'], inplace=True)\n",
    "\n",
    "    df = df_final\n",
    "\n",
    "    df[\"dateCreated\"] = pd.to_datetime(df[\"dateCreated\"]).apply(lambda x: x.strftime(\"%Y-%m\"))\n",
    "    df[\"dateCrawled\"] = pd.to_datetime(df[\"dateCrawled\"]).apply(lambda x: x.strftime(\"%Y-%m\"))\n",
    "    df[\"lastSeen\"] = pd.to_datetime(df[\"lastSeen\"]).apply(lambda x: x.strftime(\"%Y-%m\"))\n",
    "\n",
    "    print(\"Encoding...\")\n",
    "    onehot = OneHotEncoder()\n",
    "    trans_one_hot = onehot.fit_transform(df[[\"abtest\"]])\n",
    "    oh_df = pd.DataFrame(trans_one_hot.toarray(), columns=onehot.get_feature_names_out())\n",
    "\n",
    "    df = pd.concat([df.reset_index(drop=True), oh_df.reset_index(drop=True)], axis=1)\n",
    "\n",
    "    df.drop(columns=[\"seller\", \"offerType\", \"abtest\"], inplace=True)\n",
    "    df.reset_index(drop=True, inplace=True)\n",
    "    encoder = TargetEncoder(cols = df.select_dtypes(\"O\").columns)\n",
    "    df_encoded = encoder.fit_transform(X = df, y = df[\"price\"])\n",
    "    df = df_encoded\n",
    "    print(\"Creating Model..\")\n",
    "    X = df.drop(columns= [\"price\"])\n",
    "    y = df[\"price\"]\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "    print(X_train.dtypes)\n",
    "\n",
    "    decision_tree = DecisionTreeRegressor()\n",
    "    grid_search = GridSearchCV(estimator=decision_tree, param_grid=params_tree, cv = 5, scoring=\"neg_mean_squared_error\")\n",
    "    grid_search.fit(X_train, y_train)\n",
    "    best_tree = grid_search.best_estimator_\n",
    "\n",
    "    y_train_pred = best_tree.predict(X = X_train)\n",
    "    y_test_pred = best_tree.predict(X = X_test)\n",
    "\n",
    "    metrics = pd.DataFrame(metricas(y_train, y_train_pred, y_test, y_test_pred)).T\n",
    "\n",
    "    display(metrics)\n",
    "\n",
    "    plt.figure(dpi = 140, figsize = (6,4))\n",
    "    sns.scatterplot(x = y_test, y = abs(y_test_pred-y_test))\n",
    "    plt.ylabel(\"Error absoluto\")\n",
    "    plt.xlabel(\"Precio real\")\n",
    "    plt.show()\n",
    "    return best_tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"datos/df_final.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Applying IFO\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [07:40<00:00, 18.40s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Applying LOF\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [02:11<00:00,  5.24s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoding...\n",
      "Creating Model..\n",
      "Unnamed: 0             float64\n",
      "dateCrawled            float64\n",
      "vehicleType            float64\n",
      "yearOfRegistration     float64\n",
      "gearbox                float64\n",
      "powerCV                float64\n",
      "kilometer              float64\n",
      "monthOfRegistration    float64\n",
      "fuelType               float64\n",
      "brand                  float64\n",
      "notRepairedDamage      float64\n",
      "dateCreated            float64\n",
      "lastSeen               float64\n",
      "lof_15_0.010             int32\n",
      "lof_15_0.058             int32\n",
      "lof_15_0.105             int32\n",
      "lof_15_0.153             int32\n",
      "lof_15_0.200             int32\n",
      "lof_22_0.010             int32\n",
      "lof_22_0.058             int32\n",
      "lof_22_0.105             int32\n",
      "lof_22_0.153             int32\n",
      "lof_22_0.200             int32\n",
      "lof_30_0.010             int32\n",
      "lof_30_0.058             int32\n",
      "lof_30_0.105             int32\n",
      "lof_30_0.153             int32\n",
      "lof_30_0.200             int32\n",
      "lof_37_0.010             int32\n",
      "lof_37_0.058             int32\n",
      "lof_37_0.105             int32\n",
      "lof_37_0.153             int32\n",
      "lof_37_0.200             int32\n",
      "lof_45_0.010             int32\n",
      "lof_45_0.058             int32\n",
      "lof_45_0.105             int32\n",
      "lof_45_0.153             int32\n",
      "lof_45_0.200             int32\n",
      "abtest_control         float64\n",
      "abtest_test            float64\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "get_ml_model(df, params_tree=params_tree, scaler_type=\"rob\", outlier_threshold=60)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
